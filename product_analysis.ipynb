{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd8dbf8",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565af6f3",
   "metadata": {},
   "source": [
    "\n",
    "# Marketing Campaign Analytics â€” EDA, Segmentation & Insights\n",
    "\n",
    "**Dataset:** Kaggle Marketing Campaign (customer-level)  \n",
    "**Goal:** Analyze customer behavior, segment customers (RFM & K-Means), and assess campaign performance to produce consulting-style insights and visuals.\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Load & clean data (handles separators, dates, missing values)\n",
    "2. Feature engineering (Total Spend, Frequency, Campaign metrics)\n",
    "3. KPI snapshot\n",
    "4. EDA visuals (spend distribution, spend by demographics, purchases by channel)\n",
    "5. RFM segmentation (quartiles) + interpretation\n",
    "6. Optional K-Means clustering on RFM features\n",
    "7. Campaign effectiveness analysis by segment and demographics\n",
    "8. Save cleaned dataset & figures\n",
    "\n",
    "> Run cells top-to-bottom. Figures will be saved to `figures/` for your README and dashboard.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfab79",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Section 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a146c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib defaults\n",
    "plt.rcParams['figure.figsize'] = (9, 5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = \"marketing_campaign.csv\"  # dataset in same folder\n",
    "OUTPUT_DIR = \".\"                      # save outputs in current folder\n",
    "FIG_DIR = os.path.join(OUTPUT_DIR, \"figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf609c7",
   "metadata": {},
   "source": [
    "## 1) Load & Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d379da6",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 2: Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf071c",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Section 2: Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15c51a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'marketing_campaign.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load with correct separator\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarketing_campaign.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Clean column names\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\disha\\anaconda3\\envs\\campusx\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\disha\\anaconda3\\envs\\campusx\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\disha\\anaconda3\\envs\\campusx\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\disha\\anaconda3\\envs\\campusx\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\disha\\anaconda3\\envs\\campusx\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'marketing_campaign.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load with correct separator\n",
    "df = pd.read_csv('marketing_campaign.csv', sep=';')\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Convert date\n",
    "if 'dt_customer' in df.columns:\n",
    "    df['dt_customer'] = pd.to_datetime(df['dt_customer'], errors='coerce')\n",
    "\n",
    "# Handle missing values (median for income)\n",
    "if 'income' in df.columns:\n",
    "    df['income'] = df['income'].fillna(df['income'].median())\n",
    "\n",
    "# Feature engineering\n",
    "spend_cols = ['mntwines','mntfruits','mntmeatproducts','mntfishproducts','mntsweetproducts','mntgoldprods']\n",
    "df['total_spend'] = df[spend_cols].sum(axis=1)\n",
    "\n",
    "# Frequency of purchases\n",
    "purchase_cols = ['numdealspurchases','numwebpurchases','numcatalogpurchases','numstorepurchases']\n",
    "df['frequency'] = df[purchase_cols].sum(axis=1)\n",
    "\n",
    "# Total campaigns accepted (Cmp1-5), and last response\n",
    "campaign_cols = ['acceptedcmp1','acceptedcmp2','acceptedcmp3','acceptedcmp4','acceptedcmp5']\n",
    "existing_campaign_cols = [c for c in campaign_cols if c in df.columns]\n",
    "df['total_campaigns_accepted'] = df[existing_campaign_cols].sum(axis=1) if existing_campaign_cols else 0\n",
    "if 'response' not in df.columns:\n",
    "    df['response'] = 0  # fallback\n",
    "\n",
    "# Basic sanity checks\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "print(\"Sample columns:\", df.columns[:10].tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250f1a5",
   "metadata": {},
   "source": [
    "## 2) KPI Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2994d7",
   "metadata": {},
   "source": [
    "### ðŸ§ª Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc247c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kpis = {}\n",
    "\n",
    "kpis['total_customers'] = len(df)\n",
    "kpis['avg_income'] = float(df['income'].mean()) if 'income' in df.columns else None\n",
    "kpis['avg_total_spend'] = float(df['total_spend'].mean())\n",
    "kpis['median_total_spend'] = float(df['total_spend'].median())\n",
    "kpis['overall_campaign_response_rate'] = float(df['response'].mean()) if 'response' in df.columns else None\n",
    "kpis['overall_cmp_accepts_rate'] = float((df['total_campaigns_accepted'] > 0).mean())\n",
    "\n",
    "print(\"KPI Snapshot:\")\n",
    "for k, v in kpis.items():\n",
    "    print(f\" - {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610a7db",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 3: Key Business KPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e075e",
   "metadata": {},
   "source": [
    "## 3) EDA â€” Distributions & Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2708a8",
   "metadata": {},
   "source": [
    "### ðŸ§ª Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1 Distribution of total spend\n",
    "plt.figure()\n",
    "plt.hist(df['total_spend'], bins=30)\n",
    "plt.title('Distribution of Total Spend')\n",
    "plt.xlabel('Total Spend')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'dist_total_spend.png'))\n",
    "plt.show()\n",
    "\n",
    "# 3.2 Total spend by education (average)\n",
    "if 'education' in df.columns:\n",
    "    spend_by_edu = df.groupby('education')['total_spend'].mean().sort_values(ascending=False)\n",
    "    plt.figure()\n",
    "    spend_by_edu.plot(kind='bar')\n",
    "    plt.title('Average Total Spend by Education')\n",
    "    plt.xlabel('Education')\n",
    "    plt.ylabel('Average Total Spend')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'avg_spend_by_education.png'))\n",
    "    plt.show()\n",
    "\n",
    "# 3.3 Total spend by marital status (average)\n",
    "if 'marital_status' in df.columns:\n",
    "    spend_by_ms = df.groupby('marital_status')['total_spend'].mean().sort_values(ascending=False)\n",
    "    plt.figure()\n",
    "    spend_by_ms.plot(kind='bar')\n",
    "    plt.title('Average Total Spend by Marital Status')\n",
    "    plt.xlabel('Marital Status')\n",
    "    plt.ylabel('Average Total Spend')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'avg_spend_by_marital_status.png'))\n",
    "    plt.show()\n",
    "\n",
    "# 3.4 Income vs Total Spend\n",
    "if 'income' in df.columns:\n",
    "    plt.figure()\n",
    "    plt.scatter(df['income'], df['total_spend'], alpha=0.5)\n",
    "    plt.title('Income vs Total Spend')\n",
    "    plt.xlabel('Income')\n",
    "    plt.ylabel('Total Spend')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'income_vs_total_spend.png'))\n",
    "    plt.show()\n",
    "\n",
    "# 3.5 Purchases by channel (average per customer)\n",
    "channel_cols = ['numwebpurchases','numcatalogpurchases','numstorepurchases']\n",
    "present_channels = [c for c in channel_cols if c in df.columns]\n",
    "if present_channels:\n",
    "    avg_by_channel = df[present_channels].mean().sort_values(ascending=False)\n",
    "    plt.figure()\n",
    "    avg_by_channel.plot(kind='bar')\n",
    "    plt.title('Average Purchases by Channel')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Avg Purchases')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'avg_purchases_by_channel.png'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753f75b",
   "metadata": {},
   "source": [
    "## 4) RFM Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa2547",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 4: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ade3f9",
   "metadata": {},
   "source": [
    "### ðŸ§¹ Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RFM components:\n",
    "# R = 'recency' (lower is better / more recent)\n",
    "# F = 'frequency' (higher better)\n",
    "# M = 'total_spend' (higher better)\n",
    "\n",
    "# Guard against duplicate bin edges using duplicates='drop'\n",
    "rfm = df.copy()\n",
    "\n",
    "# Ensure no negative or NaNs\n",
    "rfm['recency'] = rfm['recency'].fillna(rfm['recency'].median())\n",
    "rfm['frequency'] = rfm['frequency'].fillna(0)\n",
    "rfm['total_spend'] = rfm['total_spend'].fillna(0)\n",
    "\n",
    "# Create quartile segments\n",
    "recency_labels = ['Very Recent','Recent','Moderate','Inactive']\n",
    "frequency_labels = ['Low','Medium','High','Very High']\n",
    "monetary_labels = ['Low','Medium','High','Very High']\n",
    "\n",
    "try:\n",
    "    rfm['recency_segment'] = pd.qcut(rfm['recency'], 4, labels=recency_labels, duplicates='drop')\n",
    "except Exception as e:\n",
    "    print(\"Recency qcut warning:\", e)\n",
    "    rfm['recency_segment'] = pd.qcut(rfm['recency'].rank(method='first'), 4, labels=recency_labels)\n",
    "\n",
    "try:\n",
    "    rfm['frequency_segment'] = pd.qcut(rfm['frequency'], 4, labels=frequency_labels, duplicates='drop')\n",
    "except Exception as e:\n",
    "    print(\"Frequency qcut warning:\", e)\n",
    "    rfm['frequency_segment'] = pd.qcut(rfm['frequency'].rank(method='first'), 4, labels=frequency_labels)\n",
    "\n",
    "try:\n",
    "    rfm['monetary_segment'] = pd.qcut(rfm['total_spend'], 4, labels=monetary_labels, duplicates='drop')\n",
    "except Exception as e:\n",
    "    print(\"Monetary qcut warning:\", e)\n",
    "    rfm['monetary_segment'] = pd.qcut(rfm['total_spend'].rank(method='first'), 4, labels=monetary_labels)\n",
    "\n",
    "rfm['rfm_segment'] = rfm['recency_segment'].astype(str) + '-' + rfm['frequency_segment'].astype(str) + '-' + rfm['monetary_segment'].astype(str)\n",
    "\n",
    "# Segment sizes\n",
    "seg_counts = rfm['rfm_segment'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top RFM segments by count:\")\n",
    "print(seg_counts.head(10))\n",
    "\n",
    "# Plot segment counts (top 12 for readability)\n",
    "top_n = seg_counts.head(12)\n",
    "plt.figure()\n",
    "top_n.plot(kind='bar')\n",
    "plt.title('Top RFM Segments by Count')\n",
    "plt.xlabel('RFM Segment')\n",
    "plt.ylabel('Customers')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'rfm_segment_counts.png'))\n",
    "plt.show()\n",
    "\n",
    "# Merge RFM back to main df\n",
    "df = df.merge(rfm[['id','recency_segment','frequency_segment','monetary_segment','rfm_segment']], on='id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10736cd",
   "metadata": {},
   "source": [
    "## 5) Campaign Effectiveness by Segment & Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ae1e7",
   "metadata": {},
   "source": [
    "### ðŸ§ª Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Acceptance rate by RFM segment (using 'response' as last campaign response)\n",
    "if 'response' in df.columns:\n",
    "    acc_by_rfm = df.groupby('rfm_segment')['response'].mean().sort_values(ascending=False)\n",
    "    print(\"Last-campaign response rate by RFM segment (top 10):\")\n",
    "    print((acc_by_rfm*100).round(2).head(10))\n",
    "\n",
    "    plt.figure()\n",
    "    acc_by_rfm.head(12).plot(kind='bar')\n",
    "    plt.title('Response Rate by RFM Segment (Last Campaign)')\n",
    "    plt.xlabel('RFM Segment')\n",
    "    plt.ylabel('Response Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'response_rate_by_rfm.png'))\n",
    "    plt.show()\n",
    "\n",
    "# Acceptance vs demographics\n",
    "if 'education' in df.columns and 'response' in df.columns:\n",
    "    acc_by_edu = df.groupby('education')['response'].mean().sort_values(ascending=False)\n",
    "    plt.figure()\n",
    "    acc_by_edu.plot(kind='bar')\n",
    "    plt.title('Response Rate by Education')\n",
    "    plt.xlabel('Education')\n",
    "    plt.ylabel('Response Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'response_rate_by_education.png'))\n",
    "    plt.show()\n",
    "\n",
    "if 'marital_status' in df.columns and 'response' in df.columns:\n",
    "    acc_by_ms = df.groupby('marital_status')['response'].mean().sort_values(ascending=False)\n",
    "    plt.figure()\n",
    "    acc_by_ms.plot(kind='bar')\n",
    "    plt.title('Response Rate by Marital Status')\n",
    "    plt.xlabel('Marital Status')\n",
    "    plt.ylabel('Response Rate')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'response_rate_by_marital_status.png'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86aed32",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 5: Customer Segmentation (RFM Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010739b",
   "metadata": {},
   "source": [
    "## 6) (Optional) K-Means Clustering on RFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93979644",
   "metadata": {},
   "source": [
    "### ðŸ§¹ Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6717a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Prepare RFM features\n",
    "X = rfm[['recency','frequency','total_spend']].copy()\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Simple 3-cluster solution\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "rfm['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Profile clusters\n",
    "cluster_profile = rfm.groupby('cluster')[['recency','frequency','total_spend']].mean().round(2)\n",
    "print(\"Cluster profile (means):\")\n",
    "print(cluster_profile)\n",
    "\n",
    "# Merge cluster back\n",
    "df = df.merge(rfm[['id','cluster']], on='id', how='left')\n",
    "\n",
    "# Plot cluster sizes\n",
    "cluster_counts = rfm['cluster'].value_counts().sort_index()\n",
    "plt.figure()\n",
    "cluster_counts.plot(kind='bar')\n",
    "plt.title('Cluster Sizes (K=3)')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Customers')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'cluster_sizes.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7a5e7",
   "metadata": {},
   "source": [
    "## 7) Auto-Generated Insight Starters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c777d",
   "metadata": {},
   "source": [
    "# ðŸ“‚ Section 6: Conclusions & Business Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62111649",
   "metadata": {},
   "source": [
    "### ðŸ§ª Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4975b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insights = []\n",
    "\n",
    "# High-value customers threshold\n",
    "hi_spend_thresh = df['total_spend'].quantile(0.8)\n",
    "hi_val_share = (df['total_spend'] >= hi_spend_thresh).mean()\n",
    "\n",
    "insights.append(f\"Top 20% customers account for ~{hi_val_share*100:.1f}% of the base (define tailored retention campaigns).\")\n",
    "\n",
    "# Best responding RFM segment (if computed)\n",
    "if 'response' in df.columns and 'rfm_segment' in df.columns:\n",
    "    resp_by_seg = df.groupby('rfm_segment')['response'].mean().sort_values(ascending=False)\n",
    "    if len(resp_by_seg) > 0:\n",
    "        top_seg, top_rate = resp_by_seg.index[0], resp_by_seg.iloc[0]*100\n",
    "        insights.append(f\"Best last-campaign response segment: **{top_seg}** at ~{top_rate:.1f}% response. Prioritize this segment for the next campaign.\")\n",
    "\n",
    "# Education / Marital signals\n",
    "if 'education' in df.columns and 'response' in df.columns:\n",
    "    best_edu = df.groupby('education')['response'].mean().sort_values(ascending=False).index[0]\n",
    "    insights.append(f\"Highest response by education group: **{best_edu}**. Consider tailored creatives for this cohort.\")\n",
    "\n",
    "if 'marital_status' in df.columns and 'response' in df.columns:\n",
    "    best_ms = df.groupby('marital_status')['response'].mean().sort_values(ascending=False).index[0]\n",
    "    insights.append(f\"Highest response by marital status: **{best_ms}**.\")\n",
    "\n",
    "for i, s in enumerate(insights, 1):\n",
    "    print(f\"{i}. {s}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340a41c",
   "metadata": {},
   "source": [
    "## 8) Save Cleaned Dataset & Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f721dee6",
   "metadata": {},
   "source": [
    "### ðŸ§ª Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_path = os.path.join(OUTPUT_DIR, \"clean_marketing_campaign.csv\")\n",
    "df.to_csv(clean_path, index=False)\n",
    "print(\"Saved cleaned dataset to:\", clean_path)\n",
    "print(\"Figures saved to:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da673fe9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Notebook generated:** 2025-09-05 13:41:59 UTC  \n",
    "\n",
    "**Next steps (for portfolio):**\n",
    "- Add 3â€“5 bullet insights to your README\n",
    "- Insert key figures from `figures/`\n",
    "- Build a Tableau/Power BI dashboard using `clean_marketing_campaign.csv`\n",
    "- Write a short executive summary like a consultant\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "campusx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
